{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738090927.826997 5615202 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "I0000 00:00:1738090927.839689 5615202 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "W0000 00:00:1738090927.877034 5623458 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738090927.890451 5623458 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738090927.973226 5623455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clique em dois pontos para definir uma distância de 33 cm. Pressione 'Q' para continuar o processamento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1738090928.086210 5623455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Processando Vídeo: 100%|██████████| 2335/2335 [04:18<00:00,  9.02frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo concluído! Vídeo salvo como /Users/borba/Desktop/video_tracked_Bruna.mp4 e dados salvos como /Users/borba/Desktop/hand_tracking_data_Bruna.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "Name = 'Bruna'  # Nome do arquivo de saída\n",
    "\n",
    "# Caminhos de input e output\n",
    "VIDEO_INPUT_PATH = \"/Users/borba/Desktop/bruna.mp4\"  # Caminho do vídeo de entrada\n",
    "VIDEO_OUTPUT_PATH = f\"/Users/borba/Desktop/video_tracked_{Name}.mp4\"  # Caminho do vídeo de saída\n",
    "EXCEL_OUTPUT_PATH = f\"/Users/borba/Desktop/hand_tracking_data_{Name}.xlsx\"  # Caminho do Excel de saída\n",
    "\n",
    "# Inicializar MediaPipe Pose e Hands\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7, model_complexity=2)\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=2)\n",
    "\n",
    "# Função para suavização (média móvel)\n",
    "def smooth_points(history, new_point, maxlen=5):\n",
    "    if new_point:\n",
    "        history.append(new_point)\n",
    "        smoothed_point = np.mean(history, axis=0)\n",
    "        return tuple(map(int, smoothed_point))\n",
    "    return None\n",
    "\n",
    "# Função para calcular pixels/cm\n",
    "def get_pixel_to_cm_ratio(frame):\n",
    "    print(\"Clique em dois pontos para definir uma distância de 33 cm. Pressione 'Q' para continuar o processamento.\")\n",
    "    points = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            if len(points) == 2:\n",
    "                cv2.line(frame, points[0], points[1], (0, 255, 0), 2)\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.setMouseCallback(\"Frame\", mouse_callback)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Pressionar 'Q' para sair\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(points) == 2:\n",
    "        pixel_distance = np.linalg.norm(np.array(points[0]) - np.array(points[1]))\n",
    "        return pixel_distance / 33  # 33 cm de referência\n",
    "    else:\n",
    "        raise ValueError(\"Você deve selecionar exatamente dois pontos.\")\n",
    "\n",
    "# Carregar o vídeo\n",
    "cap = cv2.VideoCapture(VIDEO_INPUT_PATH)\n",
    "\n",
    "# Obter informações do vídeo\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Criar um novo vídeo para salvar a saída\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(VIDEO_OUTPUT_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Obter a proporção pixels/cm no primeiro frame\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(\"Não foi possível ler o vídeo.\")\n",
    "pixel_to_cm_ratio = get_pixel_to_cm_ratio(first_frame)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reiniciar o vídeo para o início\n",
    "\n",
    "# Criar históricos para suavização\n",
    "history = {\n",
    "    \"Shoulder_R\": deque(maxlen=5), \"Elbow_R\": deque(maxlen=5), \"Wrist_R\": deque(maxlen=5), \"MCP_R\": deque(maxlen=5),\n",
    "    \"Shoulder_L\": deque(maxlen=5), \"Elbow_L\": deque(maxlen=5), \"Wrist_L\": deque(maxlen=5), \"MCP_L\": deque(maxlen=5)\n",
    "}\n",
    "\n",
    "# Criar lista para armazenar dados\n",
    "data = []\n",
    "\n",
    "# Criar barra de progresso\n",
    "progress_bar = tqdm.tqdm(total=total_frames, desc=\"Processando Vídeo\", unit=\"frame\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Calcular o tempo correspondente ao frame\n",
    "    time = frame_count / fps\n",
    "\n",
    "    # Processar a pose\n",
    "    pose_results = pose.process(image_rgb)\n",
    "\n",
    "    # Inicializar pontos do corpo\n",
    "    shoulder_r = elbow_r = wrist_r = mcp_r = None\n",
    "    shoulder_l = elbow_l = wrist_l = mcp_l = None\n",
    "\n",
    "    if pose_results.pose_landmarks:\n",
    "        landmarks = pose_results.pose_landmarks.landmark\n",
    "\n",
    "        # Lado direito\n",
    "        shoulder_r = smooth_points(history[\"Shoulder_R\"], \n",
    "                                   (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * frame_width,\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * frame_height))\n",
    "        elbow_r = smooth_points(history[\"Elbow_R\"], \n",
    "                                (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x * frame_width,\n",
    "                                 landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y * frame_height))\n",
    "\n",
    "        # Lado esquerdo\n",
    "        shoulder_l = smooth_points(history[\"Shoulder_L\"], \n",
    "                                   (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * frame_width,\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame_height))\n",
    "        elbow_l = smooth_points(history[\"Elbow_L\"], \n",
    "                                (landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * frame_width,\n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * frame_height))\n",
    "\n",
    "    # Processar as mãos\n",
    "    hands_results = hands.process(image_rgb)\n",
    "\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            # Determinar se é a mão direita ou esquerda\n",
    "            hand_type = \"R\" if i == 0 else \"L\"\n",
    "\n",
    "            # Ponto 0 (WRIST) e ponto 5 (MCP)\n",
    "            wrist = smooth_points(history[f\"Wrist_{hand_type}\"], \n",
    "                                  (hand_landmarks.landmark[0].x * frame_width,\n",
    "                                   hand_landmarks.landmark[0].y * frame_height))\n",
    "            mcp = smooth_points(history[f\"MCP_{hand_type}\"], \n",
    "                                (hand_landmarks.landmark[5].x * frame_width,\n",
    "                                 hand_landmarks.landmark[5].y * frame_height))\n",
    "\n",
    "            if hand_type == \"R\":\n",
    "                wrist_r, mcp_r = wrist, mcp\n",
    "            else:\n",
    "                wrist_l, mcp_l = wrist, mcp\n",
    "\n",
    "    # Adicionar dados ao array\n",
    "    data.append([\n",
    "        frame_count, time,\n",
    "        mcp_r[0] if mcp_r else None, mcp_r[1] if mcp_r else None,\n",
    "        wrist_r[0] if wrist_r else None, wrist_r[1] if wrist_r else None,\n",
    "        elbow_r[0] if elbow_r else None, elbow_r[1] if elbow_r else None,\n",
    "        shoulder_r[0] if shoulder_r else None, shoulder_r[1] if shoulder_r else None,\n",
    "        mcp_l[0] if mcp_l else None, mcp_l[1] if mcp_l else None,\n",
    "        wrist_l[0] if wrist_l else None, wrist_l[1] if wrist_l else None,\n",
    "        elbow_l[0] if elbow_l else None, elbow_l[1] if elbow_l else None,\n",
    "        shoulder_l[0] if shoulder_l else None, shoulder_l[1] if shoulder_l else None,\n",
    "    ])\n",
    "\n",
    "    # Desenhar os pontos no vídeo\n",
    "    for point, color in zip(\n",
    "        [shoulder_r, elbow_r, wrist_r, mcp_r, shoulder_l, elbow_l, wrist_l, mcp_l],\n",
    "        [(255, 0, 0)] * 8  # Todos os pontos em vermelho\n",
    "    ):\n",
    "        if point:\n",
    "            cv2.circle(frame, tuple(map(int, point)), 8, color, -1)\n",
    "\n",
    "    # Escrever no novo vídeo\n",
    "    out.write(frame)\n",
    "\n",
    "    # Atualizar barra de progresso\n",
    "    progress_bar.update(1)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "progress_bar.close()\n",
    "\n",
    "# Salvar dados em um arquivo Excel\n",
    "columns = [\n",
    "    \"Frame\", \"Time\",\n",
    "    \"MCP_R_X\", \"MCP_R_Y\", \"Wrist_R_X\", \"Wrist_R_Y\", \"Elbow_R_X\", \"Elbow_R_Y\", \"Shoulder_R_X\", \"Shoulder_R_Y\",\n",
    "    \"MCP_L_X\", \"MCP_L_Y\", \"Wrist_L_X\", \"Wrist_L_Y\", \"Elbow_L_X\", \"Elbow_L_Y\", \"Shoulder_L_X\", \"Shoulder_L_Y\"\n",
    "]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_excel(EXCEL_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Processo concluído! Vídeo salvo como {VIDEO_OUTPUT_PATH} e dados salvos como {EXCEL_OUTPUT_PATH}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
